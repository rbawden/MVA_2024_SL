# MVA. Algorithms for speech and natural language processing

## Basic information

- Topic: Machine Translation
- Teacher: Rachel Bawden
- Date and time: Friday 15th March 2024, 4pm-7pm
- Place: Salle Dussanne, 45 rue d'Ulm

## Reading and links

If you're interesting in going further...

- Opus parallel data repository: https://opus.nlpl.eu
- Evaluation:
  - Sacrebleu: Standard implementation of BLEU: https://github.com/mjpost/sacrebleu
  - Comet: https://unbabel.github.io/COMET/html/index.html
- Speech and Language Processing by Jurafsky and Martin:
  - N-gram language models: https://web.stanford.edu/~jurafsky/slp3/3.pdf
  - RNNs and LSTMS: https://web.stanford.edu/~jurafsky/slp3/9.pdf
  - Transformers and Large Language Models: https://web.stanford.edu/~jurafsky/slp3/10.pdf
  - Machine Translation: https://web.stanford.edu/~jurafsky/slp3/13.pdf
- Some major papers:
  - Neural MT (seq2seq without attention): Sutskever et al., (2014). Sequence to Sequence Learning with Neural Networks: https://arxiv.org/abs/1409.3215
  - Neural MT with attention: Bahdanau et al. (2015). Neural Machine Translation by Jointly Learning to Align and Translate: https://arxiv.org/abs/1409.0473
  - Transformer: Vaswani et al., (2017). Attention Is All You Need. https://arxiv.org/abs/1706.03762
  - Universal multilingual MT: Johnson et al., (2017): Google's Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation: [https://arxiv.org/abs/1611.04558](https://aclanthology.org/Q17-1024/)https://aclanthology.org/Q17-1024/
  - BLEU: Papineni et al. (2002). Bleu: a Method for Automatic Evaluation of Machine Translation: https://aclanthology.org/P02-1040/:
  - COMET: Rei et al., (2020). COMET: A Neural Framework for MT Evaluation: https://aclanthology.org/2020.emnlp-main.213/

